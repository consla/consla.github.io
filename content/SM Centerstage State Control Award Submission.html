<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url(https://themes.googleusercontent.com/fonts/css?kit=8apCgqRrTD4kFh3_sUrApkKKYS4hv_rnLQzFi6X1UhM);ol{margin:0;padding:0}table td,table th{padding:0}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Average";font-style:normal}.c4{color:#e3b426;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Average";font-style:normal}.c8{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:18pt;font-family:"Average";font-style:normal}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:justify;height:11pt}.c0{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c5{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c7{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c10{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c14{text-decoration:none;vertical-align:baseline;font-style:normal}.c18{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c3{font-family:"Average";color:#6aa84f;font-weight:700}.c19{color:#000000;font-weight:400;font-family:"Arial"}.c12{font-weight:700;font-family:"Average"}.c17{border:1px solid black;margin:5px}.c9{font-weight:400;font-family:"Average"}.c11{font-size:11pt}.c13{color:#e3b426}.c6{height:11pt}.c15{font-size:18pt}.c16{color:#cc0000}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c18 doc-content"><div><p class="c5"><span class="c12 c13 c15">Control Award</span><span class="c8">&nbsp;Submission &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; #19953 Scrap Metal</span></p></div><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 65.40px; height: 51.60px;"><img alt="" src="images/image2.png" style="width: 65.40px; height: 51.60px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c12 c13">Autonomous objectives</span></p><p class="c7"><span class="c9 c11">We knew that in this season&rsquo;s game, </span><span class="c12 c11">auto compatibility</span><span class="c2">&nbsp;with alliance partners was going to be very important in order to obtain the heavily weighted randomization points. Owing to this, our autonomous programs are structured piecewise in order to be highly composable, with paths automatically regenerated based on our starting configuration.</span></p><p class="c1"><span class="c2"></span></p><p class="c7"><span class="c9 c11">This enables us to quickly </span><span class="c3 c11">adapt to our alliance partners</span><span class="c2">&nbsp;and easily restructure our autonomous based on our alliance partner&rsquo;s needs. We can complete both the purple and yellow pixel randomizations in any starting position, optionally score 1 more white pixel if starting on the audience side, and 2 more white pixels if starting on the backdrop side.</span></p><p class="c5 c6"><span class="c2"></span></p><p class="c0"><span class="c4">Sensors used</span></p><p class="c7"><span class="c9">We used a total of </span><span class="c12">17 sensors</span><span class="c2">&nbsp;on our robot.</span></p><p class="c1"><span class="c2"></span></p><p class="c7"><span class="c12">Accurate autonomous localization:</span><span class="c2">&nbsp;2 odometry encoders, 1 REV Control Hub IMU</span></p><p class="c7"><span class="c12">Lift PID/control:</span><span class="c2">&nbsp;1 lift motor encoder</span></p><p class="c7"><span class="c12">Lift encoder reset:</span><span class="c2">&nbsp;2 lift motor current sensors</span></p><p class="c7"><span class="c12">Drivetrain characterization and robot profiling:</span><span class="c2">&nbsp;4 drive motor current sensors</span></p><p class="c7"><span class="c12">Backdrop distance detection:</span><span class="c2">&nbsp;2 infrared analog voltage distance sensors</span></p><p class="c7"><span class="c12">Outtake arm automation:</span><span class="c2">&nbsp;2 Axon Max+ servo analog encoders</span></p><p class="c7"><span class="c12">Intake automation:</span><span class="c2">&nbsp;2 REV color sensors</span></p><p class="c7"><span class="c12">Team prop detection:</span><span class="c2">&nbsp;1 camera</span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 161.50px; height: 265.92px;"><img alt="" src="images/image3.png" style="width: 161.50px; height: 265.92px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span class="c9">We </span><span class="c3">enhance our sensor data</span><span class="c9">&nbsp;through </span><span class="c3">increasing our loop frequency</span><span class="c9">&nbsp;and </span><span class="c3">regressing our sensor measurements</span><span class="c9">. In order to have well performing control algorithms, we need high loop frequencies for odometry accuracy and less feedback lag. We do this through avoiding hardware calls, like only performing hardware reads from other sensors when necessary and caching hardware writes. Through this, we improved our average loop frequencies from </span><span class="c12 c16">30 hz</span><span class="c9">&nbsp;to </span><span class="c3">250 hz</span><span class="c9">. We were able to </span><span class="c3">double the aggression</span><span class="c9">&nbsp;of the gains were in our PIDF controllers and </span><span class="c3">got rid of multiple inches of drift</span><span class="c2">&nbsp;in our auto.</span></p><p class="c1"><span class="c2"></span></p><p class="c7"><span class="c9">Additionally, our distance sensors output an analog voltage as an inverse of the distance measured. Instead of trusting the data given by the manufacturer, we plotted the received voltage to the corresponding actual distance for each individual sensor and created a regression on that data, and </span><span class="c3">getting rid of the 10% error</span><span class="c2">&nbsp;between them.</span></p><hr style="page-break-before:always;display:none;"><p class="c1"><span class="c2"></span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 65.40px; height: 51.60px;"><img alt="" src="images/image2.png" style="width: 65.40px; height: 51.60px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c12 c13">Key Algor</span><span class="c12 c13">ithms</span><sup><a href="#cmnt1" id="cmnt_ref1">[a]</a></sup></p><p class="c7"><span class="c12">Inverse kinematics:</span><span class="c9">&nbsp;Our scoring sequence is highly automated, which is detailed further below. One of the major parts of this is using inverse kinematics to </span><span class="c3">automatically compensate for varying distances</span><span class="c2">&nbsp;from the backdrop. We used trigonometry to derive equations to solve for the required lift extension and arm angle of our 2 degree of freedom outtake. This sped up our autonomous reliability and teleop cycle times, as the robot only needs to align within a 6 inch range from the backdrop and our drivers simply press one button to automatically bring our outtake to the scoring position pressed against the backdrop.</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 208.50px; height: 197.81px;"><img alt="" src="images/image4.png" style="width: 208.50px; height: 197.81px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 191.50px; height: 200.66px;"><img alt="" src="images/image6.png" style="width: 191.50px; height: 200.66px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2"></span></p><p class="c7"><span class="c12">Guiding vector fields (GVF):</span><span class="c9">&nbsp;This season, we developed our own </span><span class="c3">custom path following system</span><span class="c9">&nbsp;using an algorithm called a guiding vector field. This adds the unit tangent vector of the nearest point of the path to a weighted error vector in order to a produce a final vector that converges to the path. For paths, our system can take any parametric function, but we primarily use cubic Hermite splines (a form of Bezie&#769;r spline) to achieve smooth movement and easy path creation. Because we developed our own system, we were able to </span><span class="c3">exactly match our own specifications</span><span class="c2">&nbsp;and requirements as opposed to using a pre-built library like Roadrunner.</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 192.00px; height: 189.24px;"><img alt="" src="images/image1.png" style="width: 192.00px; height: 189.24px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5 c6"><span class="c4"></span></p><p class="c0"><span class="c4">Driver Controlled Enhancements</span></p><p class="c7"><span class="c9">Both our intake and outtake sequences are heavily automated. The intake will </span><span class="c3">automatically stop, lock the pixels, and send a rumble</span><span class="c9">&nbsp;to both of our driver controllers when it detects that 2 pixels have been intaked through a pair of color sensors. Our desired scoring height is queued instead of manually controlled by the second driver. When the primary driver is ready, they hit one button to </span><span class="c3">automatically align</span><span class="c9">&nbsp;the angle of the robot to the backdrop via a heading PIDF controller, hit the button again to bring the outtake to the backdrop at the previously queued height and automatically compensate for forward/back error via the inverse kinematics, and finally hit it one more time to release the pixels. This system </span><span class="c3">greatly reduces the cognitive load</span><span class="c9">&nbsp;on our drivers and </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 241.74px; height: 240.68px;"><img alt="" src="images/image5.png" style="width: 241.74px; height: 240.68px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c2">allows our cycle times to be much more smooth and efficient.</span></p><p class="c1"><span class="c4"></span></p><p class="c0"><span class="c4">Engineering Portfolio References</span></p><p class="c7"><span class="c2">Loop frequency + sensor regression: pg. 14<br>Inverse kinematics + GVF: pg. 15</span></p><p class="c5 c6"><span class="c4"></span></p><p class="c0"><span class="c4">Autonomous Program Diagrams</span></p><p class="c5"><span class="c2">1. Score purple preload on spike marks</span></p><p class="c5"><span class="c9">2. Score yellow preload on backdrop -&gt; park</span></p><div class="c17"><p class="c10"><a href="#cmnt_ref1" id="cmnt1">[a]</a><span class="c14 c11 c19">pics</span></p></div></body></html>